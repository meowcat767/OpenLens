window.searchData = [
  {
    "id": 5,
    "url": "https://en.wikipedia.org/wiki/PostgreSQL",
    "title": "PostgreSQL - Wikipedia",
    "content": "Jump to content From Wikipedia, the free encyclopedia Free and open-source object relational database management system PostgreSQL The World\u0027s Most Advanced Open Source Relational Database[1] Developer PostgreSQL Global Development Group[2] Initial release 8 July 1996; 29 years ago (1996-07-08)[3] Stable release 18.1[4] / 13 November 2025 Repository git.postgresql.org/gitweb/?p\u003dpostgresql.git Written in C (and C++ for the LLVM dependency) Type RDBMS License PostgreSQL License (free and open-source, permissive)[5][6][7] Website www.postgresql.org PostgreSQL License[5] Publisher PostgreSQL Global Development Group Regents of the University of California Debian FSG compatible Yes[8][9] FSF approved Yes[10] OSI approved Yes[7] GPL compatible Yes Copyleft No Linking from code with a different licence Yes Website postgresql.org/about/licence PostgreSQL (/ˌpoʊstɡrɛskjuˈɛl/ ⓘ POHST-gres-kew-EL)[11][12] also known as Postgres, is a free and open-source relational database management system (RDBMS) emphasizing extensibility and SQL compliance. PostgreSQL features transactions with atomicity, consistency, isolation, durability (ACID) properties, automatically updatable views, materialized views, triggers, foreign keys, and stored procedures.[13] It is supported on all major operating systems, including Windows, Linux, macOS, FreeBSD, and OpenBSD, and handles a range of workloads from single machines to data warehouses, data lakes,[14] or web services with many concurrent users. The PostgreSQL Global Development Group focuses only on developing a database engine and closely related components. This core is, technically, what comprises PostgreSQL itself, but there is an extensive developer community and ecosystem that provides other important feature sets that might, traditionally, be provided by a proprietary software vendor. These include special-purpose database engine features, like those needed to support a geospatial[15] or temporal[16] database or features which emulate other database products.[17][18][19][20] Also available from third parties are a wide variety of user and machine interface features, such as graphical user interfaces[21][22][23] or load balancing and high availability toolsets.[24] The large third-party PostgreSQL support network of people, companies, products, and projects, even though not part of The PostgreSQL Development Group, are essential to the PostgreSQL database engine\u0027s adoption and use and make up the PostgreSQL ecosystem writ large.[25] PostgreSQL was originally named POSTGRES, referring to its origins as a successor to the Ingres database developed at the University of California, Berkeley.[26][27] In 1996, the project was renamed PostgreSQL to reflect its support for SQL. After a review in 2007, the development team decided to keep the name PostgreSQL and the alias Postgres.[28] History [edit] Ingres and University POSTGRES (1982–1994) [edit] PostgreSQL evolved from the Ingres project at the University of California, Berkeley. In 1982, the leader of the Ingres team, Michael Stonebraker, left Berkeley to make a proprietary version of Ingres.[26] He returned to Berkeley in 1985, and began a post-Ingres project to address the problems with contemporary database systems that had become increasingly clear during the early 1980s. He won the Turing Award in 2014 for these and other projects,[29] and techniques pioneered in them. The new project, POSTGRES, aimed to add the fewest features needed to completely support data types.[30] These features included the ability to define types and to fully describe relationships – something used widely, but maintained entirely by the user. In POSTGRES, the database understood relationships, and could retrieve information in related tables in a natural way using rules. POSTGRES used many of the ideas of Ingres, but not its code.[31] Starting in 1986, published papers described the basis of the system, and a prototype version was shown at the 1988 ACM SIGMOD Conference. The team released version 1 to a small number of users in June 1989, followed by version 2 with a re-written rules system in June 1990. Version 3, released in 1991, again re-wrote the rules system, and added support for multiple storage managers[32] and an improved query engine. By 1993, the number of users began to overwhelm the project with requests for support and features. After releasing version 4.2[33] on June 30, 1994 – primarily a cleanup – the project ended. Berkeley released POSTGRES under an MIT License variant, which enabled other developers to use the code for any use. At the time, POSTGRES used an Ingres-influenced POSTQUEL query language interpreter, which could be interactively used with a console application named monitor. Postgres95 (1994–1996) [edit] In 1994, Berkeley graduate students Andrew Yu and Jolly Chen replaced the POSTQUEL query language interpreter with one for the SQL query language, creating Postgres95. The monitor console was also replaced by psql. Yu a",
    "scrapedAt": "2025-12-15 15:45:20.611235"
  },
  {
    "id": 4,
    "url": "https://en.wikipedia.org/wiki/Java_(programming_language)",
    "title": "Java (programming language) - Wikipedia",
    "content": "Jump to content From Wikipedia, the free encyclopedia Object-oriented programming language Not to be confused with JavaScript. \"Openframe\" redirects here. For the ten-pin bowling term, see Open frame. Java Paradigm Multi-paradigm: generic, object-oriented (class-based), functional, imperative, reflective, concurrent Designed by James Gosling Developer Oracle Corporation First appeared May 23, 1995; 30 years ago (1995-05-23)[1] Stable release Java SE 25[2] / 16 September 2025; 2 months ago (16 September 2025) Typing discipline Static, strong, safe, nominative, manifest Memory management Garbage-collected Filename extensions .java, .class, .jar, .jmod, .war Website oracle.com/java/ java.com dev.java Influenced by CLU,[3] Simula67,[3] Lisp,[3] Smalltalk,[3] Ada 83, C++,[4] C#,[5] Eiffel,[6] Mesa,[7] Modula-3,[8] Oberon,[9] Objective-C,[10] UCSD Pascal,[11][12] Object Pascal[13] Influenced Ada 2005, ArkTS, BeanShell, C#, Chapel,[14] Clojure, ECMAScript, Fantom, Gambas,[15] Groovy, Hack,[16] Haxe, J#, JavaScript, JS++, Kotlin, PHP, Python, Scala, Vala Java Programming at Wikibooks Java is a high-level, general-purpose, memory-safe, object-oriented programming language. It is intended to let programmers write once, run anywhere (WORA),[17] meaning that compiled Java code can run on all platforms that support Java without the need to recompile.[18] Java applications are typically compiled to bytecode that can run on any Java virtual machine (JVM) regardless of the underlying computer architecture. The syntax of Java is similar to C and C++, but has fewer low-level facilities than either of them. The Java runtime provides dynamic capabilities (such as reflection and runtime code modification) that are typically not available in traditional compiled languages. Java gained popularity shortly after its release, and has been a popular programming language since then.[19] Java was the third most popular programming language in 2022[update] according to GitHub.[20] Although still widely popular, there has been a gradual decline in use of Java in recent years with other languages using JVM gaining popularity.[21] Java was designed by James Gosling at Sun Microsystems. It was released in May 1995 as a core component of Sun\u0027s Java platform. The original and reference implementation Java compilers, virtual machines, and class libraries were released by Sun under proprietary licenses. As of May 2007, in compliance with the specifications of the Java Community Process, Sun had relicensed most of its Java technologies under the GPL-2.0-only license. Oracle, which bought Sun in 2010, offers its own HotSpot Java Virtual Machine. However, the official reference implementation is the OpenJDK JVM, which is open-source software used by most developers and is the default JVM for almost all Linux distributions. Java 25 is the version current as of September 2025[update]. Java 8, 11, 17, 21, and 25 are long-term support versions still under maintenance. History See also: Java (software platform) § History Duke, the Java mascot James Gosling, the creator of Java, in 2008 James Gosling, Mike Sheridan, and Patrick Naughton initiated the Java language project in June 1991.[22] Java was originally designed for interactive television, but it was too advanced for the digital cable television industry at the time.[23] The language was initially called Oak after an oak tree that stood outside Gosling\u0027s office. Later the project went by the name Green and was finally renamed Java, from Java coffee, a type of coffee from Indonesia.[24] Gosling designed Java with a C/C++-style syntax that system and application programmers would find familiar.[25] Sun Microsystems released the first public implementation as Java 1.0 in 1996.[26] It promised write once, run anywhere (WORA) functionality, providing no-cost run-times on popular platforms. Fairly secure and featuring configurable security, it allowed network- and file-access restrictions. Major web browsers soon incorporated the ability to run Java applets within web pages, and Java quickly became popular. The Java 1.0 compiler was re-written in Java by Arthur van Hoff to comply strictly with the Java 1.0 language specification.[27] With the advent of Java 2 (released initially as J2SE 1.2 in December 1998 – 1999), new versions had multiple configurations built for different types of platforms. J2EE included technologies and APIs for enterprise applications typically run in server environments, while J2ME featured APIs optimized for mobile applications. The desktop version was renamed J2SE. In 2006, for marketing purposes, Sun renamed new J2 versions as Java EE, Java ME, and Java SE, respectively. In 1997, Sun Microsystems approached the ISO/IEC JTC 1 standards body and later the Ecma International to formalize Java, but it soon withdrew from the process.[28][29][30] Java remains a de facto standard, controlled through the Java Community Process.[31] At one time, Sun made most of its Java implementatio",
    "scrapedAt": "2025-12-15 15:45:18.800709"
  },
  {
    "id": 3,
    "url": "https://en.wikipedia.org/wiki/Database",
    "title": "Database - Wikipedia",
    "content": "Jump to content From Wikipedia, the free encyclopedia Organized collection of data in computing This article is about the computing concept. For instances of the general concept, see Lists of databases. An SQL select statement and its result In computing, a database is an organized collection of data or a type of data store based on the use of a database management system (DBMS), the software that interacts with end users, applications, and the database itself to capture and analyze the data. The DBMS additionally encompasses the core facilities provided to administer the database. The sum total of the database, the DBMS and the associated applications can be referred to as a database system. Often the term \"database\" is also used loosely to refer to any of the DBMS, the database system or an application associated with the database. Before digital storage and retrieval of data have become widespread, index cards were used for data storage in a wide range of applications and environments: in the home to record and store recipes, shopping lists, contact information and other organizational data; in business to record presentation notes, project research and notes, and contact information; in schools as flash cards or other visual aids; and in academic research to hold data such as bibliographical citations or notes in a card file. Professional book indexers used index cards in the creation of book indexes until they were replaced by indexing software in the 1980s and 1990s. Small databases can be stored on a file system, while large databases are hosted on computer clusters or cloud storage. The design of databases spans formal techniques and practical considerations, including data modeling, efficient data representation and storage, query languages, security and privacy of sensitive data, and distributed computing issues, including supporting concurrent access and fault tolerance. Computer scientists may classify database management systems according to the database models that they support. Relational databases became dominant in the 1980s. These model data as rows and columns in a series of tables, and the vast majority use SQL for writing and querying data. In the 2000s, non-relational databases became popular, collectively referred to as NoSQL, because they use different query languages. Terminology and overview Formally, a \"database\" refers to a set of related data accessed through the use of a \"database management system\" (DBMS), which is an integrated set of computer software that allows users to interact with one or more databases and provides access to all of the data contained in the database (although restrictions may exist that limit access to particular data). The DBMS provides various functions that allow entry, storage and retrieval of large quantities of information and provides ways to manage how that information is organized. Because of the close relationship between them, the term \"database\" is often used casually to refer to both a database and the DBMS used to manipulate it. Outside the world of professional information technology, the term database is often used to refer to any collection of related data (such as a spreadsheet or a card index) as size and usage requirements typically necessitate use of a database management system.[1] Existing DBMSs provide various functions that allow management of a database and its data which can be classified into four main functional groups: Data definition – Creation, modification and removal of definitions that detail how the data is to be organized. Update – Insertion, modification, and deletion of the data itself.[2] Retrieval – Selecting data according to specified criteria (e.g., a query, a position in a hierarchy, or a position in relation to other data) and providing that data either directly to the user, or making it available for further processing by the database itself or by other applications. The retrieved data may be made available in a more or less direct form without modification, as it is stored in the database, or in a new form obtained by altering it or combining it with existing data from the database.[3] Administration – Registering and monitoring users, enforcing data security, monitoring performance, maintaining data integrity, dealing with concurrency control, and recovering information that has been corrupted by some event such as an unexpected system failure.[4] Both a database and its DBMS conform to the principles of a particular database model.[5] \"Database system\" refers collectively to the database model, database management system, and database.[6] Physically, database servers are dedicated computers that hold the actual databases and run only the DBMS and related software. Database servers are usually multiprocessor computers, with generous memory and RAID disk arrays used for stable storage. Hardware database accelerators, connected to one or more servers via a high-speed channel, are also used in large-volume t",
    "scrapedAt": "2025-12-15 15:45:17.111473"
  },
  {
    "id": 2,
    "url": "https://en.wikipedia.org/wiki/Web_scraping",
    "title": "Web scraping - Wikipedia",
    "content": "Jump to content From Wikipedia, the free encyclopedia For broader coverage of this topic, see Data scraping. Method of extracting data from websites \"Web scraper\" redirects here. For websites that scrape content, see Scraper site. This article needs additional citations for verification. Please help improve this article by adding citations to reliable sources. Unsourced material may be challenged and removed. Find sources: \"Web scraping\" – news · newspapers · books · scholar · JSTOR (April 2023) (Learn how and when to remove this message) Web scraping, web harvesting, or web data extraction is data scraping used for extracting data from websites.[1] Web scraping software may directly access the World Wide Web using the Hypertext Transfer Protocol or a web browser. While web scraping can be done manually by a software user, the term typically refers to automated processes implemented using a bot or web crawler. It is a form of copying in which specific data is gathered and copied from the web, typically into a central local database or spreadsheet, for later retrieval or analysis. Scraping a web page involves fetching it and then extracting data from it. Fetching is the downloading of a page (which a browser does when a user views a page). Therefore, web crawling is a main component of web scraping, to fetch pages for later processing. Having fetched, extraction can take place. The content of a page may be parsed, searched and reformatted, and its data copied into a spreadsheet or loaded into a database. Web scrapers typically take something out of a page, to make use of it for another purpose somewhere else. An example would be finding and copying names and telephone numbers, companies and their URLs, or e-mail addresses to a list (contact scraping). As well as contact scraping, web scraping is used as a component of applications used for web indexing, web mining and data mining, online price change monitoring and price comparison, product review scraping (to watch the competition), gathering real estate listings, weather data monitoring, website change detection, research, tracking online presence and reputation, web mashup, and web data integration. Web pages are built using text-based mark-up languages (HTML and XHTML), and frequently contain a wealth of useful data in text form. However, most web pages are designed for human end-users and not for ease of automated use. As a result, specialized tools and software have been developed to facilitate the scraping of web pages. Web scraping applications include market research, price comparison, content monitoring, and more. Businesses rely on web scraping services to efficiently gather and utilize this data. Newer forms of web scraping involve monitoring data feeds from web servers. For example, JSON is commonly used as a transport mechanism between the client and the web server. There are methods that some websites use to prevent web scraping, such as detecting and disallowing bots from crawling (viewing) their pages. In response, web scraping systems use techniques involving DOM parsing, computer vision and natural language processing to simulate human browsing to enable gathering web page content for offline parsing. History [edit] After the birth of the World Wide Web in 1989, the first web robot,[2] World Wide Web Wanderer, was created in June 1993, which was intended only to measure the size of the web. In December 1993, the first crawler-based web search engine, JumpStation, was launched. As there were fewer websites available on the web, search engines at that time used to rely on human administrators to collect and format links. In comparison, Jump Station was the first WWW search engine to rely on a web robot. In 2000, the first Web API and API crawler were created. An API (Application Programming Interface) is an interface that makes it much easier to develop a program by providing the building blocks. In 2000, Salesforce and eBay launched their own API, with which programmers could access and download some of the data available to the public.[3] Since then, many websites offer web APIs for people to access their public database. Techniques [edit] This section contains instructions or advice. Wikipedia is not a guidebook; please help rewrite such content to be encyclopedic or move it to Wikiversity, Wikibooks, or Wikivoyage. (October 2025) Web scraping is the process of automatically mining data or collecting information from the World Wide Web. It is a field with active developments sharing a common goal with the semantic web vision, an ambitious initiative that still requires breakthroughs in text processing, semantic understanding, artificial intelligence and human-computer interactions. Human copy-and-paste [edit] The simplest form of web scraping is manually copying and pasting data from a web page into a text file or spreadsheet. Sometimes even the best web-scraping technology cannot replace a human\u0027s manual examination and copy-and-paste, a",
    "scrapedAt": "2025-12-15 15:45:15.62867"
  },
  {
    "id": 1,
    "url": "https://en.wikipedia.org/wiki/Search_engine",
    "title": "Search engine - Wikipedia",
    "content": "Jump to content From Wikipedia, the free encyclopedia Software system for finding relevant information on the Web This article is about searching the World Wide Web. For other uses, see Search engine (disambiguation). This article\u0027s tone or style may not reflect the encyclopedic tone used on Wikipedia. See Wikipedia\u0027s guide to writing better articles for suggestions. (June 2025) (Learn how and when to remove this message) A Google search result for the phrase \"magic flute opera\" A search engine is a software system that provides hyperlinks to web pages, and other relevant information on the Web in response to a user\u0027s query. The user enters a query in a web browser or a mobile app, and the search results are typically presented as a list of hyperlinks accompanied by textual summaries and images. Users also have the option of limiting a search to specific types of results, such as images, videos, or news. For a search provider, its engine is part of a distributed computing system that can encompass many data centers throughout the world. The speed and accuracy of an engine\u0027s response to a query are based on a complex system of indexing that is continuously updated by automated web crawlers. This can include data mining the files and databases stored on web servers, although some content is not accessible to crawlers. There have been many search engines since the dawn of the Web in the 1990s; however, Google Search became the dominant one in the 2000s and has remained so. As of May 2025, according to StatCounter, Google holds approximately 89–90 % of the worldwide search share, with competitors trailing far behind: Bing (~4 %), Yandex (~2.5 %), Yahoo! (~1.3 %), DuckDuckGo (~0.8 %), and Baidu (~0.7 %).[1] Notably, this marks the first time in over a decade that Google\u0027s share has fallen below the 90% threshold. The business of websites improving their visibility in search results, known as marketing and optimization, has thus largely focused on Google. History Further information: Timeline of web search engines Timeline (full list) Year Engine Current status 1993 W3Catalog Inactive ALIWEB Inactive JumpStation Inactive WWW Worm Inactive 1994 WebCrawler Active Go.com Inactive, redirects to Disney Lycos Active Infoseek Inactive, redirects to Disney 1995 Yahoo! Search Active, initially a search function for Yahoo! Directory Daum Active Search.ch Active Magellan Inactive Excite Active MetaCrawler Active AltaVista Inactive, acquired by Yahoo! in 2003, since 2013 redirects to Yahoo! SAPO Active 1996 RankDex Inactive, incorporated into Baidu in 2000 Dogpile Active HotBot Inactive (used Inktomi search technology) Ask Jeeves Active (rebranded ask.com) 1997 AOL NetFind Active (rebranded AOL Search since 1999) goo.ne.jp Active Northern Light Inactive Yandex Active 1998 Google Active Ixquick Active as Startpage.com MSN Search Active as Bing empas Inactive (merged with NATE) 1999 AlltheWeb Inactive (URL redirected to Yahoo!) GenieKnows Inactive, rebranded Yellowee (was redirecting to justlocalbusiness.com) Naver Active Teoma Inactive (redirect to Ask.com) 2000 Baidu Active Exalead Inactive Gigablast Inactive 2001 Kartoo Inactive 2003 Info.com Active 2004 A9.com Inactive Clusty Active, Yippy, previously Clusty, now owns Togoda.com Mojeek Active Sogou Active 2005 SearchMe Inactive KidzSearch Active, Google Search 2006 Soso Inactive, merged with Sogou Quaero Inactive Search.com Active ChaCha Inactive Ask.com Active Live Search Active as Bing, rebranded MSN Search 2007 wikiseek Inactive Sproose Inactive Wikia Search Inactive Blackle.com Active, Google Search 2008 Powerset Inactive (redirects to Bing) Picollator Inactive Viewzi Inactive Boogami Inactive LeapFish Inactive Forestle Inactive (redirects to Ecosia) DuckDuckGo Active TinEye Active 2009 Bing Active, rebranded Live Search Yebol Inactive Scout (Goby) Active NATE Active Ecosia Active Startpage.com Active, sister engine of Ixquick 2010 Blekko Inactive, sold to IBM Cuil Inactive Yandex (English) Active Parsijoo Active 2011 YaCy Active, P2P 2012 Volunia Inactive 2013 Qwant Active 2014 Egerin Active, Kurdish / Sorani Swisscows Active Searx Active 2015 Yooz Inactive Cliqz Inactive 2016 Kiddle Active, Google Search 2017 Presearch Active 2018 Kagi Active 2020 Petal Active 2021 Brave Search Active You.com Active Pre-1990s In 1945, Vannevar Bush described an information retrieval system that would allow a user to access a great expanse of information, all at a single desk, which he called a memex.[2] He described this system in an article titled \"As We May Think\" in The Atlantic Monthly.[3] The memex was intended to give a user the capability to overcome the ever-increasing difficulty of locating information in ever-growing centralized indices of scientific work. Vannevar Bush envisioned libraries of research with connected annotations, which are similar to modern hyperlinks.[4] Link analysis eventually became a crucial component of search engines through algorithms such as Hyper ",
    "scrapedAt": "2025-12-15 15:45:13.987035"
  }
];